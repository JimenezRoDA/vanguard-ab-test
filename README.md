# ğŸ§  Vanguard A/B Test Analysis â€“ Funnel Optimization

## ğŸ§© Business Context

> Vanguard, a global investment management leader, recently launched a **digital redesign** of its customer onboarding experience. To assess the true impact of this redesign, the company conducted an **A/B test**.  
Users were randomly assigned to either the **control group** (original user journey) or the **treatment group** (newly redesigned flow). The objective:  
> **Measure if the redesign leads to a higher funnel completion rate, fewer drop-offs, and better user experience.**

> [!NOTE]
> This project simulates a real-life product experiment. It was developed during a Data Analysis Bootcamp to replicate decision-making scenarios based on real A/B testing data.

---

<details>
<summary>ğŸ“¦ <strong>Dataset Overview</strong></summary>

The dataset consists of user navigation events throughout the onboarding funnel:

- `user_id`: Unique identifier per user.
- `group`: A/B group label â€“ `control` or `treatment`.
- `step`: Funnel step (e.g., `step_1`, `step_2`, ..., `confirm`).
- `timestamp`: Timestamp of the event.
- Derived fields (created in preprocessing):
  - `time_diff`: Time difference between steps.
  - `final_step`: Last recorded step per user.
  - `error_flags`: Indicators for anomalies.

</details>

---

<details>
<summary>ğŸ§¹ <strong>Data Cleaning & Wrangling</strong></summary>

To ensure valid insights, we applied rigorous data preprocessing steps:

- Chronologically sorted user steps.
- Removed sessions with:
  - Repeated steps (e.g., multiple `step_2`s).
  - Backward jumps (e.g., `step_3` to `step_1`).
  - Zero-second step transitions.
- Labeled sessions that did **not** end in `confirm` as **abandonments**.
- Engineered features for:
  - Time spent per step.
  - Funnel depth reached.
  - Navigation consistency.

> These cleaning rules were based on domain assumptions. In a production setting, more session metadata and UX feedback would further guide this logic.

</details>

---

<details>
<summary>ğŸ“Š <strong>Exploratory Data Analysis</strong></summary>

The EDA compared control vs. treatment groups on multiple dimensions:

- **Completion Rate** â€“ % of users reaching the `confirm` step.
- **Drop-off Points** â€“ Common exit steps.
- **Navigation Errors** â€“ Frequency of repeated or reversed steps.
- **Time Metrics** â€“ Total and per-step time comparisons.

Key visualizations:
- Funnel diagrams by group
- Step-wise conversion rates
- Session length distributions

</details>

---

<details>
<summary>ğŸ§ª <strong>Hypothesis Testing</strong></summary>

We ran statistical tests to validate whether differences observed were statistically significant:

- âœ… **Z-test for proportions** (completion rate comparison).
- âœ… **T-test** / **Mann-Whitney U test** (time differences).
- âœ… **Chi-squared test** (distribution of final steps and errors).
- âœ… **Sanity checks** for group balance and random assignment.

Assumptions tested:
- Normality (Shapiro-Wilk, histograms).
- Equal variances (Levene's test).

> Statistical significance â‰  business impact. All insights were contextualized with user experience and operational considerations.

</details>

---

<details>
<summary>ğŸ“ˆ <strong>Key Insights</strong></summary>

- âœ… **Higher completion rate** in the treatment group (statistically significant).
- ğŸ”„ **Fewer navigation errors** post-redesign, especially backward transitions.
- â±ï¸ **Time efficiency** slightly improved but not statistically conclusive.
- ğŸ§© Users followed a more linear path in the redesigned flow.

</details>

---

<details>
<summary>ğŸ§­ <strong>Recommendations</strong></summary>

- âœ… **Roll out the redesign** to the broader user base.
- ğŸ“Š Monitor funnel metrics continuously to detect regressions.
- ğŸ”¬ Run additional segmented tests (e.g., new vs. returning users).
- ğŸ§  Gather qualitative UX insights (e.g., via surveys, heatmaps).
- âš™ï¸ Improve experiment design with longer run times and controlled traffic splits.

</details>

---

## ğŸ‘¥ Authors

[![Xavi](https://img.shields.io/badge/@xavistem-GitHub-181717?logo=github&style=flat-square)](https://github.com/xavistem)  
[![RocÃ­o JimÃ©nez](https://img.shields.io/badge/@JimenezRoDA-GitHub-181717?logo=github&style=flat-square)](https://github.com/JimenezRoDA)


## ğŸ§‘â€ğŸ« Educational Context

This analysis was developed as part of a Data Analytics Bootcamp.  
It reflects industry-standard approaches to experimentation, data cleaning, and interpretation of A/B tests within digital products.
